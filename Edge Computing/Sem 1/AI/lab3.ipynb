{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e10d0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:58:55.183035: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-13 16:58:55.183133: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-13 16:58:55.183156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-13 16:58:55.190726: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 16:58:57.765100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.771003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.771067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from timeit import repeat\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "!rm -rf ./logs/\n",
    "\n",
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe934054",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def neural_net(x: tf.Tensor, w1: tf.Tensor, w2: tf.Tensor, b1: tf.Tensor, b2: tf.Tensor):\n",
    "    assert x.dtype == tf.float32\n",
    "    assert w1.dtype == tf.float32\n",
    "    assert w2.dtype == tf.float32\n",
    "    assert b1.dtype == tf.float32\n",
    "    assert b2.dtype == tf.float32\n",
    "    assert x.shape == (10,) or x.shape == (1, 10)\n",
    "    \n",
    "    x = tf.reshape(x, [1, 10])\n",
    "    layer1 = x @ w1 + b1 # matmul (@), bo to siec gleboka    \n",
    "    layer2 = tf.sigmoid(layer1) @ w2 + b2\n",
    "    \n",
    "    y = tf.sigmoid(layer2)\n",
    "    return y\n",
    "\n",
    "def neural_net_undecorated(x: tf.Tensor, w1: tf.Tensor, w2: tf.Tensor, b1: tf.Tensor, b2: tf.Tensor):\n",
    "    assert x.dtype == tf.float32\n",
    "    assert w1.dtype == tf.float32\n",
    "    assert w2.dtype == tf.float32\n",
    "    assert b1.dtype == tf.float32\n",
    "    assert b2.dtype == tf.float32\n",
    "    assert x.shape == (10,) or x.shape == (1, 10)\n",
    "\n",
    "    x = tf.reshape(x, [1, 10])\n",
    "    layer1 = x @ w1 + b1 # matmul (@), bo to siec gleboka    \n",
    "    layer2 = tf.sigmoid(layer1) @ w2 + b2\n",
    "    \n",
    "    y = tf.sigmoid(layer2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cfff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:58:57.805673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.805808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.805858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.928374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.928443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.928452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1974] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-13 16:58:57.928491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-13 16:58:57.928515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1503 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "logdir = 'logs/func/lab3'\n",
    "writer = tf.summary.create_file_writer(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d7808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1380: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.start` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:58:58.034456: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-03-13 16:58:58.034507: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-03-13 16:58:58.034609: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1694] Profiler found 1 GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.85 0.86 0.76 0.73 0.95 0.5  0.5  0.5  0.5  0.5 ], shape=(10,), dtype=float32) \n",
      "--->\n",
      " tf.Tensor([[0.9977336]], shape=(1, 1), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1431: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1431: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/profiler.py:150: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "tf.Tensor([0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.67 0.87], shape=(10,), dtype=float32) \n",
      "--->\n",
      " tf.Tensor([[0.00667112]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:58:58.595389: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-03-13 16:58:58.596178: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1828] CUPTI activity buffer flushed\n",
      "2024-03-13 16:58:58.600917: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_collector.cc:541]  GpuTracer has collected 19 callback api events and 17 activity events. \n",
      "2024-03-13 16:58:58.601356: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.constant([[ 1.4334732, -1.5244598 , 1.139654 , 2.723477, 2.372128, -1.8221221],\n",
    "                  [ 1.6633688, -1.3922757, 2.0349483, 1.6314147, 1.6997916, -1.719175],\n",
    "                  [ 1.6464833, -1.6136154, 1.6790704, 2.1913328, 1.7154503, -2.122219],\n",
    "                  [ 2.2029521, -2.2169485, 1.1411709, 1.7363839, 1.9620435, -1.990284],\n",
    "                  [ 1.864349, -1.9724554, 1.282788, 1.3895663 , 1.2881863, -1.3681948],\n",
    "                  [ 0.4421571, 0.24537054, 0.49080196, -0.0939824, 0.36308903, -0.32526237],\n",
    "                  [-1.6102886, 1.7532632, -1.3683709, -1.2728035, -1.8335032, 1.6637068],\n",
    "                  [-1.0453694, 0.95990705, -1.913037, -1.637573 , -1.8312218, 1.9757035],\n",
    "                  [-2.6982157, 1.5073962, -2.243781, -2.7327728 , -2.5648139, 1.9095569],\n",
    "                  [-2.0628226, 2.3980575, -1.3550557, -2.1798916 , -2.1485612, 2.2912557]], tf.float32)\n",
    "\n",
    "b1 = tf.constant([-1.6460503, 1.5486399, -1.5155386, -1.6247352, -1.2638505, 1.5515162], tf.float32)\n",
    "w2 = tf.constant([[ 2.220895 ], [-2.903738 ], [ 1.7675139], [ 2.3042984], [ 2.6292808], [-2.763858 ]], tf.float32)\n",
    "b2 = tf.constant([-1.1827456], tf.float32)\n",
    "x1 = tf.constant([0.85, 0.86, 0.76, 0.73, 0.95, 0.5, 0.5, 0.5, 0.5, 0.5], tf.float32)\n",
    "x2 = tf.constant([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.67, 0.87], tf.float32)\n",
    "\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "print(x1, \"\\n--->\\n\", neural_net(x1, w1, w2, b1, b2))\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name=\"neural_net\",\n",
    "        step=0,\n",
    "        profiler_outdir=logdir)\n",
    "print(x2, \"\\n--->\\n\", neural_net(x2, w1, w2, b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab15fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c26e27767fb943a6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c26e27767fb943a6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3637f5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas z dekoratorem (x1): 0.0016411504749985397 \n",
      "Czas z dekoratorem (x2): 0.0010549790709974331\n",
      "\n",
      "Czas bez dekoratora (x1): 0.0009853551579935812 \n",
      "Czas bez dekoratora (x2): 0.0009218312649800282\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "#for _ in range(3):\n",
    "#    neural_net(x1, w1, w2, b1, b2)\n",
    "#    neural_net(x2, w1, w2, b1, b2)\n",
    "#elapsed = time.time() - start\n",
    "neural_net(x1, w1, w2, b1, b2)\n",
    "neural_net(x2, w1, w2, b1, b2)\n",
    "print(\"Czas z dekoratorem (x1):\",    np.mean(repeat(lambda: neural_net(x1, w1, w2, b1, b2), number=1, repeat=1000)),\n",
    "      \"\\nCzas z dekoratorem (x2):\",  np.mean(repeat(lambda: neural_net(x2, w1, w2, b1, b2), number=1, repeat=1000)))\n",
    "#start = time.time()\n",
    "#for _ in range(3):\n",
    "#    neural_net_undecorated(x1, w1, w2, b1, b2)\n",
    "#    neural_net_undecorated(x2, w1, w2, b1, b2)\n",
    "#elapsed = time.time() - start\n",
    "print(\"\\nCzas bez dekoratora (x1):\",  np.mean(repeat(lambda: neural_net_undecorated(x1, w1, w2, b1, b2), number=1, repeat=1000)),\n",
    "      \"\\nCzas bez dekoratora (x2):\",  np.mean(repeat(lambda: neural_net_undecorated(x2, w1, w2, b1, b2), number=1, repeat=1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d5ec6",
   "metadata": {},
   "source": [
    "Dlaczego??\n",
    "\n",
    "> Unfortunately, tf.function is not always faster for small computations. The reason is quite simple: calling an empty tf.function is more expensive than calling an empty Python function. This is especially true when the computations involve scalars, when the speed gained inside the function is too small to recover the cost of calling it.  ~mdanatg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589afa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
